# ğŸ¤Ÿ HANDSPEAK: Real-Time Sign Language Recognition System

## ğŸ“Œ Project Overview
**HANDSPEAK** is a real-time sign language recognition system that converts hand gestures into both **text** and **speech**. It uses a webcam feed to detect signs, processes them using a deep learning model, and then outputs the corresponding character using both a visual and audible response.

> ğŸŒ Bridging the gap between hearing and non-hearing communities through AI.

---

## ğŸ¯ Key Features
- ğŸ¥ Real-time sign detection using webcam
- âœ‹ Hand tracking using MediaPipe
- ğŸ¤– CNN deep learning model for gesture classification
- ğŸ”Š Voice output using pyttsx3
- ğŸ“„ On-screen text display
- ğŸ’¡ Easy to expand to new gestures or words

---

## ğŸ§  Technologies Used
| Area             | Tools / Libraries                     |
|------------------|----------------------------------------|
| Programming      | Python                                 |
| Vision           | OpenCV, Mediapipe                      |
| AI/ML            | TensorFlow, Keras                      |
| Speech           | pyttsx3 (Text-to-Speech)               |
| UI               | OpenCV GUI (basic interface)           |
| Data             | ASL or ISL Sign Language Datasets      |

---

## ğŸ“ Project Structure

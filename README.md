# 🤟 HANDSPEAK: Real-Time Sign Language Recognition System

## 📌 Project Overview
**HANDSPEAK** is a real-time sign language recognition system that converts hand gestures into both **text** and **speech**. It uses a webcam feed to detect signs, processes them using a deep learning model, and then outputs the corresponding character using both a visual and audible response.

> 🌍 Bridging the gap between hearing and non-hearing communities through AI.

---

## 🎯 Key Features
- 🎥 Real-time sign detection using webcam
- ✋ Hand tracking using MediaPipe
- 🤖 CNN deep learning model for gesture classification
- 🔊 Voice output using pyttsx3
- 📄 On-screen text display
- 💡 Easy to expand to new gestures or words

---

## 🧠 Technologies Used
| Area             | Tools / Libraries                     |
|------------------|----------------------------------------|
| Programming      | Python                                 |
| Vision           | OpenCV, Mediapipe                      |
| AI/ML            | TensorFlow, Keras                      |
| Speech           | pyttsx3 (Text-to-Speech)               |
| UI               | OpenCV GUI (basic interface)           |
| Data             | ASL or ISL Sign Language Datasets      |

---

## 📁 Project Structure
